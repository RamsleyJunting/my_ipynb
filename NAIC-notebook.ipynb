{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、解题思路说明\n",
    "\n",
    "## 待解决的问题\n",
    "1. 训练集样本数少，且各id下的图片量分布严重不平衡，接近一半的id只有1张图片，需要对训练集进行增强处理。\n",
    "2. 图片经过特殊加密处理，大部分图片的细节接近丢失，颜色信息不可用，需要使用鲁棒性和表征能力更强的深度模型和损失函数确保类内相似度高，类间相似度低。\n",
    "3. 数据集规模较小，需要抑制过拟合\n",
    "\n",
    "## 整体思路/方案\n",
    "1. 使用***gaussian_blur***, ***mirror***, ***rotation***, ***resize_blur***, ***random_erasing***增强训练集数据，使用训练集的总体均值和方差做normalization。\n",
    "2. 使用更大的w***eight_decay***和***dropout ratio***抵抗过拟合。\n",
    "3. 为了获得更好的行人特征，采用***se_resnet_101_ibn_a***作为主干网络，最后一个layer的stride设为1，以减少下采样带来的信息损失，考虑到比赛所用的图片经过特殊预处理，基本只保留了全局信息，局部特征较为模糊，分类层采用***2-branch-PCB***，并使用BN层替代全连接层，进一步保留特征信息。\n",
    "3. 使用rerank，使用先验信息对gallery进行聚类，优化排序结果。\n",
    "\n",
    "## 数据处理\n",
    "1. 读取训练集的路径信息，联合标签信息生成训练集，并从训练集中分割出校验集用于模型评估，保存为txt文件，每一行为图片的绝对路径和对应标签，格式为：\n",
    "```\n",
    "abs_path_0 label_0\n",
    "abs_path_1 label_1\n",
    "abs_path_2 label_2\n",
    "...\n",
    "abs_path\n",
    "```\n",
    "2. 使用训练好的模型反馈数据，提取训练集特征，使用层级聚类清洗训练集，去除重复图片。\n",
    "3. 在线训练时使用上述所示的各种增强方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据清洗代码使用示例\n",
    "SOURCE_TXT=\"path to your source trainset.txt to be cleaned\"\n",
    "SUB_WORKING_DIR=\"your sub working dir where you save the model\"\n",
    "CLEANED_OUTPUT_PATH=\"path to save your new trainset.txt after datacleaning\"\n",
    "GPU=0\n",
    "\n",
    "# Start data clean\n",
    "cd tools/\n",
    "python3 data_clean.py --source_txt $SOURCE_TXT --sub_working_dir $SUB_WORKING_DIR --output_path $CLEANED_OUTPUT_PATH --drop_min 0 --clean_min 50 --gpu $GPU "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 模型训练（损失函数）\n",
    "   1. 本算法的模型训练分为两个阶段，第一阶段训练只包含***CrosseEntrophy Loss***的模型。\n",
    "   2. 待模型收敛之后，开始第二阶段训练。第二阶段模型使用一阶段模型作为预训练模型，使用***Triplte Loss***和***CrosseEntrophy Loss***共同训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CrosseEntrophy Loss\n",
    "nn.CrossEntropyLoss()\n",
    "\n",
    "## Triplete Loss\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.ranking_loss = nn.MarginRankingLoss(margin=margin, reduce=False) \\\n",
    "            if margin != \"soft_margin\" else nn.SoftMarginLoss(reduce=False)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.softmin = nn.Softmin(dim=1)\n",
    "\n",
    "    def forward(self, inputs, targets, step):\n",
    "        # P x K\n",
    "        n = inputs.size(0)\n",
    "\n",
    "        # (optional) used ft_norm only on finetune situaation\n",
    "        # inputs = 30 * inputs / torch.norm(inputs, p=2, dim=1, keepdim=True)\n",
    "\n",
    "        # Compute pairwise distance\n",
    "        dist = torch.pow(inputs, 2).sum(dim=1, keepdim=True).expand(n, n)\n",
    "        dist = dist + dist.t()\n",
    "        dist.addmm_(1, -2, inputs, inputs.t())\n",
    "        dist = dist.clamp(min=1e-12).sqrt()\n",
    "\n",
    "        # Batch hard mining\n",
    "        pos_mask = targets.expand(n, n).eq(targets.expand(n, n).t())\n",
    "        neg_mask = targets.expand(n, n).ne(targets.expand(n, n).t())\n",
    "        pos_dist = dist[pos_mask].contiguous().view(n, -1)\n",
    "        neg_dist = dist[neg_mask].contiguous().view(n, -1)\n",
    "        dist_ap = torch.max(pos_dist, 1, keepdim=True)[0].squeeze(1)\n",
    "        dist_an = torch.min(neg_dist, 1, keepdim=True)[0].squeeze(1)\n",
    "\n",
    "        y = dist_an.data.new().resize_as_(dist_an.data).fill_(1)\n",
    "        active_mask = dist_an.data.new().resize_as_(dist_an.data).fill_(1)\n",
    "        y.requires_grad = False\n",
    "        active_mask.requires_grad = False\n",
    "\n",
    "        # Compute loss and statistic for logging.\n",
    "        loss_mat = self.ranking_loss(dist_an, dist_ap, y) \\\n",
    "            if self.margin != \"soft_margin\"\\\n",
    "            else self.ranking_loss(dist_an - dist_ap, y)\n",
    "        loss = loss_mat.mean()\n",
    "        pull_ratio = (dist_an.data > dist_ap.data).sum().\\\n",
    "            float() * 100. / y.size(0)\n",
    "        active_triplet = active_mask[loss_mat > 0.001].sum()\n",
    "        mean_dist_an = dist_an.mean()\n",
    "        mean_dist_ap = dist_ap.mean()\n",
    "\n",
    "        return loss, pull_ratio, active_triplet, mean_dist_an, mean_dist_ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主要创新点\n",
    "1. 使用数据清洗和针对性的增强方法缓解数据不平衡等问题。\n",
    "2. 因地制宜的对主干网络进行改进，使其极大地保留了图像的特征信息，提升模型整体对图片中的弱信息的表征能力。\n",
    "3. 使用两阶段训练策略，先令模型学习各个类中心的信息，再通过额外的三元损失压缩各个类的特征空间，使得类与类之间更具区分性。\n",
    "4. 后处理的匹配阶段，通过高置信度的配对过滤掉低置信度匹配，通过聚类进行gallery的特征的优化，详细代码参考generate_result.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、项目运行环境\n",
    "## 预训练模型及相关论文\n",
    "本算法使用***se_resnet_101_ibn_a***作为主干网络，使用了IBN-Net[1]的预训练参数\n",
    "* 预训练模型下载链接为： https://drive.google.com/drive/folders/1thS2B8UOSBi_cJX6zRy6YYRwz_nVFI_S ，下载文件为***se_resnet101_ibn_a.pth.tar  ***\n",
    "* 原作者给出的代码仓库地址为：https://github.com/XingangPan/IBN-Net  \n",
    "\n",
    "[1] Xinggang Pan, Ping Luo, Jianping Shi, Xiaoou Tang. \"Two at Once: Enhancing Learning and Generalization Capacities via IBN-Net\", ECCV2018\n",
    "\n",
    "## 项目所需的工具包/框架\n",
    "* python v3.6.5\n",
    "* cuda v9.0\n",
    "* pytorch v1.1.0\n",
    "* tensorflow v1.8\n",
    "* torchvision v0.2.1\n",
    "* tensorboardX v1.6\n",
    "\n",
    "\n",
    "## 项目运行的资源环境\n",
    "\n",
    "* 4卡11G CeForce GTX 1080Ti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、项目运行办法\n",
    "## 代码托管地址\n",
    "   本算法根据大会要求托管于github私有仓库，可查看代码获得更详细的相关信息。  \n",
    "   地址为：https://github.com/RamsleyJunting/NAIC_ReID\n",
    "\n",
    "## 项目的文件结构\n",
    " |-- NAIC_ReID  \n",
    " \n",
    "    |-- params.json\n",
    "    |-- train.py\n",
    "    |-- evaluate\n",
    "        |-- __init__.py\n",
    "        |-- generate_result.py\n",
    "        |-- naic_evaluate.py\n",
    "        |-- re_ranking.py\n",
    "    |-- input_pipeline\n",
    "        |-- __init__.py\n",
    "        |-- iamge_data_reader.py\n",
    "        |-- lmdb_dataset.py\n",
    "        |-- samplers.py\n",
    "    |-- nets\n",
    "        |-- __init__.py\n",
    "        |-- layers.py\n",
    "        |-- model_main.py\n",
    "        |-- nets_factory.py\n",
    "        |-- resnet.py\n",
    "        |-- se_resnet.py\n",
    "    |-- utils\n",
    "        |-- __init__.py\n",
    "        |-- lr_scheduler.py\n",
    "        |-- model_utils.py\n",
    "        |-- training_utils.py\n",
    "\n",
    "\n",
    "## 运行步骤\n",
    "### 构建训练/校验集文本文件\n",
    "   本项目采用pytorch的Dataloader读取list文件***trainset.txt***, 文件中每一行包含了每张图片的绝对路径和标签，用空格分隔，若要使用校验集评估模型的性能，需要自行从训练集中分割出一定比例数据作为***queryset.txt***和***gallery_set.txt***，格式与***trainset.txt***保持一致，如下所示：\n",
    "```\n",
    "abs_path_0 label_0\n",
    "abs_path_1 label_1\n",
    "abs_path_2 label_2\n",
    "...\n",
    "abs_path_n label_n\n",
    "```\n",
    "### 模型训练\n",
    "   使用以下命令开始模型训练，通过***SUB_WORKING_DIR***指定模型的工作目录路径，训练过程中的train_log和模型文件将会保存在这里。***params.json***为模型训练需要的各种必要参数，对一些关键参数简要说明如下：\n",
    "   1. ***\"asoftmax_params\"***: margin_softmax参数；\n",
    "   2. ***\"batches_dir\"***: 数据集路径；\n",
    "   3. ***\"evaluation_params\"***: 在线校验参数；\n",
    "   4. ***\"tri_loss_params\"***: triplet loss参数；\n",
    "   5. ***\"working_dir\"***: 模型工作路径SUB_WORKING_DIR的父目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 train.py --config_path params.json --sub_working_dir SUB_WORKING_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 在线校验与模型预测\n",
    "   本项目包含在线校验模块，在训练过程中，通过设定***params.json***中\"evaluation_params\"-\"eval_start=k\"以及\"evaluation_params\"-\"step=n\"指示模型从第k个epoch开始，每n个epoch运行一次在线校验，并保存在校验集上表现最好的模型，保存为：***YOUR_SUB_WORKING_DIR/model_best.pth***。另外，若要单独预测校验集，请使用以下命令，若设定rerank_search，将对模型的rerank参数进行网格搜索，并将结果保存在***YOUR_SUB_WORKING_DIR/eval_log.log***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 evaluate/naic_evaluate.py --gpu 0 --sub_working_dir YOUR_SUB_WORKING_DIR --rerank_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果文件生成\n",
    "   运行以下命令以生成结果文件，其中**sub_working_dir**为模型及参数所在的目录，***k1,k2,lambda***为rerank的参数，***suffix***为自定义后缀，用于区分不同的结果文件，运行完成之后，将在evaluate/下生成***submit_suffix.json***，即为最终结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 evaluate/generate_result.py --gpu 0 --sub_working_dir YOUR_SUB_WORKING_DIR --k1 $rerank_k1 --k2 $rerank_k2 --lambda $rerank_lambda --suffix modelbest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
