{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "sys.path.append(\"/world/data-gpu-112/liliang/pytorch-reid\")\n",
    "from utils import model_utils\n",
    "import numpy as np\n",
    "from nets.model_main import ft_net\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from input_pipeline.lmdb_dataset import LMDBDataset\n",
    "import ipdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_gap = 50\n",
    "v_gap = 50\n",
    "text_gap = 45\n",
    "rows = 8\n",
    "cols = 7\n",
    "num_samples = rows*cols\n",
    "img_size = (256, 128)\n",
    "\n",
    "# pretrain_snapshot=\"/world/data-gpu-112/liliang/pytorch-output-mt/v4_resnet50_age_orilstdata/model_attr_best.pth\"\n",
    "# lmdb_path=\"/world/data-c26/liliang/person-sttribute/test-data/train/age/v4\"\n",
    "# config_path = \"/world/data-gpu-112/liliang/pytorch-reid/evaluate/test_params.json\"\n",
    "\n",
    "pretrain_snapshot=\"/world/data-gpu-112/liliang/pytorch-output/cleanv8_resnet50_corr4x144_am0.25_am0/model_best.pth\"\n",
    "lmdb_path=\"/world/data-c26/person_reid_batch/cleaned_v8\"\n",
    "config_path = \"/world/data-gpu-112/liliang/pytorch-reid/params.json\"\n",
    "\n",
    "model_name = \"resnet_50_ibn_a\"\n",
    "batch_size = num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileListJSONDataset(object):\n",
    "    def __init__(self, file_paths, img_h, img_w):\n",
    "        self.paths = []\n",
    "        self.labels = []\n",
    "        self.img_h = img_h\n",
    "        self.img_w = img_w\n",
    "\n",
    "        for line in file_paths:\n",
    "            path = line.split(\"\\t\")[0]\n",
    "            label = int(line.split(\"\\t\")[1])\n",
    "            self.paths.append(path)\n",
    "            self.labels.append(int(float(label)))\n",
    "\n",
    "        self.num_labels = len(set(self.labels))\n",
    "\n",
    "        global torch\n",
    "        self.normalize_mean = np.reshape(np.array([0.485, 0.456, 0.406]),\n",
    "                                         [3, 1, 1])\n",
    "        self.normalize_variance = np.reshape(np.array([0.229, 0.224, 0.225]),\n",
    "                                             [3, 1, 1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Read and preprocessing image\n",
    "        img = cv2.imread(path)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (self.img_w, self.img_h),\n",
    "                             interpolation=cv2.INTER_CUBIC)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = np.transpose(img, [2, 0, 1]).astype(np.float32)\n",
    "            img /= 255.0\n",
    "            img = ((img - self.normalize_mean) / self.normalize_variance)\n",
    "            img = img.astype(np.float32)\n",
    "            img = torch.from_numpy(img)\n",
    "        else:\n",
    "            img = torch.randn(3, self.img_h, self.img_w)\n",
    "            label = self.num_labels\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _forward(model, images):\n",
    "    with torch.no_grad():\n",
    "        rets = model(images)\n",
    "        rets = rets.cpu().numpy()\n",
    "    return rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_pred(model, dataloader, num_batches=1):\n",
    "    # Run evaluation\n",
    "    gt_labels = []\n",
    "    pred_labels = []\n",
    "    rand_idx = random.randint(0,100)\n",
    "    batch_count = 1\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        if idx!=rand_idx:\n",
    "            continue\n",
    "        images, labels = batch\n",
    "        images = images.cuda(0)\n",
    "\n",
    "        # Run forward\n",
    "        rets = _forward(model, images)\n",
    "\n",
    "        # Accumulate results\n",
    "        gt_labels += labels.tolist()\n",
    "\n",
    "        pred_labels += np.argmax(rets, axis=1).tolist()\n",
    "\n",
    "        if idx > 0 and idx % 500 == 0:\n",
    "            logging.info(\"[CLASSIFICATION_EVALUATION] %s/%s batches......\" %\n",
    "                         (idx, num_batches))\n",
    "        batch_count+=1\n",
    "        if batch_count>num_batches:\n",
    "            break\n",
    "    return images, gt_labels, pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval():\n",
    "    input_h=256\n",
    "    input_w=128\n",
    "    config=json.load(open(config_path,\"r\"))\n",
    "    config[\"num_labels\"] = 163400\n",
    "    model = ft_net(config, model_name, pcb_n_parts=4)\n",
    "    model_utils.restore_model(pretrain_snapshot, model)\n",
    "    model.eval()\n",
    "    model.cuda(0)\n",
    "    transforms_list = []\n",
    "    transforms_list.append(transforms.Resize((input_h, input_w)))\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    transforms_list.append(transforms.ToTensor())\n",
    "    transforms_list.append(normalize)\n",
    "    all_transforms = transforms.Compose(transforms_list)\n",
    "    dataset = LMDBDataset(        \n",
    "                lmdb_path,\n",
    "                transform=all_transforms\n",
    "            )\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=12)\n",
    "    imgs, gt_labels, pred_labels = _get_pred(model, dataloader, task_index=task_index, num_batches=1)\n",
    "    return imgs, gt_labels, pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'task_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-29bb8db72c93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mh_gap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mv_gap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m normalize_mean = np.reshape(np.array([0.485, 0.456, 0.406]),\n\u001b[1;32m      4\u001b[0m                                          [3, 1, 1])\n\u001b[1;32m      5\u001b[0m normalize_variance = np.reshape(np.array([0.229, 0.224, 0.225]),\n",
      "\u001b[0;32m<ipython-input-15-492e9833ecfd>\u001b[0m in \u001b[0;36mrun_eval\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m             )\n\u001b[1;32m     21\u001b[0m     \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'task_index' is not defined"
     ]
    }
   ],
   "source": [
    "page = np.ones(((img_size[0]+h_gap)*rows, (img_size[1]+v_gap)*cols, 3), dtype=np.uint8) * 255\n",
    "imgs, gt_labels, pred_labels = run_eval()\n",
    "normalize_mean = np.reshape(np.array([0.485, 0.456, 0.406]),\n",
    "                                         [3, 1, 1])\n",
    "normalize_variance = np.reshape(np.array([0.229, 0.224, 0.225]),\n",
    "                                             [3, 1, 1])\n",
    "np_imgs=[]\n",
    "for img in imgs:\n",
    "    img=np.array(img).astype(np.float32)\n",
    "    img = img*normalize_variance+normalize_mean\n",
    "    img*=255.0\n",
    "    img = np.transpose(img, [1,2,0]).astype(np.float32)\n",
    "    np_imgs.append(img)\n",
    "    \n",
    "age_scpoe_mapping = {0:\"0-1\", 1:\"2-5\", 2:\"6-10\", 3:\"11-15\", 4:\"16-20\", \n",
    "                    5:\"21-25\", 6:\"25-30\", 7:\"31-40\", 8:\"41-50\", \n",
    "                     9:\"51-60\", 10:\"61-80\", 11:\"80+\", }\n",
    "k=0\n",
    "for row in range(1,rows+1):\n",
    "    for col in range(1,cols+1):\n",
    "        gt_label = gt_labels[col*(row-1)+col-1]\n",
    "        pred_label = pred_labels[col*(row-1)+col-1]\n",
    "        cv2.putText(page, str(gt_label), \\\n",
    "                    ((col-1)*(img_size[1]+v_gap), (row-1)*(h_gap+img_size[0])+50), \\\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 1.5, (0,0,0), 2)\n",
    "        cv2.putText(page, str(pred_label), \\\n",
    "                    ((col-1)*(img_size[1]+v_gap)+60, (row-1)*(h_gap+img_size[0])+50), \\\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 1.5, (0,0,0), 2)\n",
    "        page[row*h_gap+(row-1)*img_size[0]:row*(h_gap+img_size[0])\\\n",
    "            , (col-1)*(v_gap+img_size[1]):col*img_size[1]+(col-1)*v_gap] \\\n",
    "            = np_imgs[k]\n",
    "        k+=1\n",
    "\n",
    "correct_count = 0\n",
    "for gt, pred in zip(gt_labels, pred_labels):\n",
    "    if gt == pred:\n",
    "        correct_count += 1\n",
    "accuracy = 1.0 * correct_count / len(gt_labels)\n",
    "print (\"ACC:%.4f\"%accuracy)\n",
    "plt.figure(figsize = (30,30))\n",
    "plt.axis('off')\n",
    "plt.imshow(cv2.cvtColor(page, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
