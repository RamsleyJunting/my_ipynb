{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## line格式检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/world/data-c22/train-data/xiaoxianli/bi/chongqing_anta827-910/31-40label/1566866407_24643467.jpg\\t5\\t5d78a7db80f3797481a7477f\\n']\n",
      "['/world/data-c22/train-data/xiaoxianli/bi/chongqing_anta827-910/31-40label/1566866407_43079797.jpg\\t5\\t5d78a7db80f3797481a74780\\n']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-6438718d987e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#         print(line.strip())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "# source_path = \"/world/data-c26/liliang/person_attribute/v5/lst/age/source/v5_anta3_11-25.json\"\n",
    "source_path = \"/world/data-c9/dl-data/587708b9603073b127434c32/5d82e88ca07f176fa47b9e27/15688603000730.9526127707718031_list.json\"\n",
    "with open(source_path, \"r\") as f:\n",
    "    for line in f:\n",
    "#         line = line.replace(\"\\t\", \" \")\n",
    "#         print(line.strip())\n",
    "        print(line.split(\" \"))\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tab 转空格（跑完keypoints之后用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish, total: 73827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "ori_path = \"/world/data-c26/liliang/person_attribute/v5/lst/age/source/v5_anta4_31-40.json\"\n",
    "new_path = \"/world/data-c26/liliang/person_attribute/v5/lst/age/source/v5_anta3_31-40_sp.json\"\n",
    "new_f = open(new_path, \"w\")\n",
    "cnt = 0\n",
    "with open(ori_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        if len(line)<40:\n",
    "            print(line)\n",
    "            continue\n",
    "        line = line.replace(\"\\t\", \" \")\n",
    "        new_f.write(line)\n",
    "        cnt += 1\n",
    "    print(\"finish, total: %s\"%cnt)\n",
    "new_f.close()\n",
    "call([\"rm\", ori_path]) \n",
    "call([\"mv\", new_path, ori_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## json筛选 （先根据原有分布选择upper_bound的值）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 1, 2: 1, 3: 1, 4: 801, 5: 801, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1}\n",
      "finish selecting\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "def select_json():\n",
    "    task = \"age\"\n",
    "    source_path = \"/world/data-c26/liliang/person_attribute/v5/lst/%s/source/v5_total_add.json\"%task\n",
    "    out_path = os.path.join(os.path.dirname(source_path), \"v5_select.json\")\n",
    "    recs = open(source_path, \"r\").readlines()\n",
    "    age_mapping = {0:0, 1:1, 2:2, 3:3, 4:4, 5:5, 12:6, 6:7, 7:8, 8:9, 9:10, 10:11}\n",
    "#     upper_bound = {3: 20000, 4: 20000, 5:20000, 6:17741, 7:17741}\n",
    "    upper_bound = {0:0, 1:0, 2:0, 3:0, 4:800, 5:800, 6:0, 7:0, 8:0, 9:0, 10:0, 11:0}\n",
    "    cnt_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0, 10:0, 11:0}\n",
    "\n",
    "    with open(out_path, \"w\") as out_f:\n",
    "        for line in recs:\n",
    "            path, label, keypoints = line.split(\" \")\n",
    "            label = int(label)\n",
    "            if label in [11, 13]:continue\n",
    "            label = age_mapping[label]\n",
    "            if label in upper_bound.keys() and cnt_dict[label]>upper_bound[label]:\n",
    "                continue\n",
    "            cnt_dict[label]+=1\n",
    "            out_f.write(line)\n",
    "    print(cnt_dict)\n",
    "    print(\"finish selecting\")\n",
    "\n",
    "select_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拼接json（两个version）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_keypoints_before_v5.json: 573532 records\n",
      "v5_select.json: 1612 records\n",
      "[age] finish concating, total: 575144 records\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def json_concat():\n",
    "    task = \"age\"\n",
    "    base_path = \"/world/data-c26/liliang/person_attribute/v5/lst/%s\"%task\n",
    "    last_version_path = os.path.join(base_path, \"source/train_keypoints_before_v5.json\")\n",
    "    this_version_path_1 = os.path.join(base_path, \"source/train_keypoints_v5.json\")\n",
    "    this_version_path_2 = os.path.join(base_path, \"source/v5_anta1_11-25_filtercam.json\")\n",
    "    this_version_path_3 = os.path.join(base_path, \"source/v5_anta2_11-25_filtercam.json\")\n",
    "    this_version_path_4 = os.path.join(base_path, \"source/v5_anta3_11-25_filtercam.json\")\n",
    "    this_version_path_5 = os.path.join(base_path, \"source/v5_anta4_31-40_filtercam.json\")\n",
    "    out_json_path = os.path.join(base_path, \"train_keypoints.json\")\n",
    "\n",
    "    ## for age distribution select\n",
    "    this_version_path_6 = os.path.join(base_path, \"source/v5_select.json\")\n",
    "    out_json_path = os.path.join(\"/world/data-c26/liliang/person_attribute/v5/lst/age_test_8h8h\", \"train_keypoints.json\")\n",
    "#     out_json_path = os.path.join(base_path, \"source/v5_total_add.json\")\n",
    "\n",
    "    file_paths_tobe_concat = [last_version_path, this_version_path_6]\n",
    "    total_rec = []\n",
    "\n",
    "    for fp in file_paths_tobe_concat:\n",
    "        rec = open(fp, \"r\").readlines()\n",
    "        total_rec += rec\n",
    "        print(\"%s: %s records\"%(fp.split(\"/\")[-1], len(rec)))\n",
    "\n",
    "    with open(out_json_path, \"w\") as out_f:\n",
    "        for line in total_rec:\n",
    "            out_f.write(line)\n",
    "\n",
    "    print(\"[%s] finish concating, total: %s records\"%(task, len(total_rec)))\n",
    "\n",
    "json_concat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 去除line中的cid（如有必要，跑完keypoints之后用, tab转空格之后）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish filtering\n"
     ]
    }
   ],
   "source": [
    "from subprocess import call\n",
    "def filter_cid():\n",
    "    task = \"age\"\n",
    "    source_path = \"/world/data-c26/liliang/person_attribute/v5/lst/%s/source/v5_anta4_31-40.json\"%task\n",
    "    filter_path = source_path.split(\".\")[0] + \"_filtercam.json\"\n",
    "\n",
    "    recs = open(source_path, \"r\").readlines()\n",
    "\n",
    "    with open(filter_path, \"w\") as out_f:\n",
    "        for line in recs:\n",
    "            path, label, cid, keypoints = line.split(\" \")\n",
    "            new_line = path + \" \" + label + \" \" + keypoints\n",
    "            out_f.write(new_line)\n",
    "\n",
    "    print(\"finish filtering\")\n",
    "    call([\"rm\", source_path]) \n",
    "\n",
    "filter_cid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 备份导出数据，改json中图片路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from subprocess import call\n",
    "import ipdb\n",
    "\n",
    "base_path = \"/world/data-c26/liliang/anta_json\"\n",
    "paths = [\"lehuameilan\"]\n",
    "for p in paths:\n",
    "    this_path = os.path.join(base_path, p) + \".json\"\n",
    "    chg_path = os.path.join(base_path, p) + \"_new.json\"\n",
    "    recs = open(this_path, \"r\").readlines()\n",
    "    with open(chg_path, \"w\") as out_f:\n",
    "        for line in recs:\n",
    "            path, infos = line.split(\"\\t\")\n",
    "            filename = path.split(\"/\")[-1]\n",
    "            new_path = \"/world/data-c40/liliang/\" + p + \"/\" + filename\n",
    "            new_line = new_path + \"\\t\" + infos\n",
    "            out_f.write(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
